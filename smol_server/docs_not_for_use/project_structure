smol_server/
├── main.py                    # Main entry point and server
├── pyproject.toml            # Project dependencies and metadata
├── src/
│   ├── __init__.py
│   ├── config.py             # Configuration settings
│   ├── client/
│   │   ├── __init__.py      # Client package exports
│   │   ├── agent.py         # Agent implementations
│   │   ├── llm.py           # LLM setup and configuration
│   │   └── mcp_client.py    # MCP client implementation
│   ├── data/                 # Data storage directory
│   └── utils/                # Utility functions
│       └── __init__.py
└── tools/                    # Custom tools directory
    └── database_tools.py
--

modelling_project/
├── main.py                    # Main entry point and server

├── src/
│   ├── __init__.py
│   ├── config.py             # Configuration settings
│   ├── client/
│   │   ├── ui/
│   │   ├── __init__.py      # Client package exports
│   │   ├── agent.py         # Agent implementations
│   │   ├── llm.py           # LLM setup and configuration
│   │   └── mcp_client.py    # MCP client implementation
│   ├── data/                 # Data storage directory
│   └── utils/                # Utility functions
│       └── __init__.py
└── tools/                    # Custom tools directory
    └── database_tools.py


import pandas as pd
from sqlalchemy import create_engine, text
from smolagents import tool

@tool
def clean_reviews_database(chunk_size: int = 100) -> str:
    """
    Reads the reviews table from SQLite database in chunks, cleans the data,
    and writes back the cleaned data.

    Parameters:
    chunk_size (int): Number of records to process at once. Defaults to 100.

    Returns:
    str: Success message with cleaning statistics
    """
    # Create database connection
    engine = create_engine('sqlite:///src/data/tg_database.db')

    # Read the entire table into a DataFrame
    df = pd.read_sql('SELECT * FROM tg_reviews_table', engine)

    # Store original shape for reporting
    original_na_count = df.isna().sum().sum()

    # Basic cleaning operations
    # Fill numeric columns with appropriate values
    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns
    for col in numeric_columns:
        df[col] = df[col].fillna(df[col].median())

    # Fill categorical columns with mode
    categorical_columns = df.select_dtypes(include=['object']).columns
    for col in categorical_columns:
        df[col] = df[col].fillna(df[col].mode()[0])

    # Write the cleaned DataFrame back to the database
    # Use 'replace' to overwrite the existing table
    df.to_sql('tg_reviews_table', engine, if_exists='replace', index=False)

    final_na_count = df.isna().sum().sum()

    return f"""Cleaning completed successfully:
    - Total records processed: {len(df)}
    - NA values before cleaning: {original_na_count}
    - NA values after cleaning: {final_na_count}
    - Columns cleaned: {list(df.columns)}"""
---
@tool
def clean_reviews_database_in_chunks(chunk_size: int = 100) -> str:
    """
    Reads and processes the database in chunks
    """
    engine = create_engine('sqlite:///src/data/tg_database.db')

    # Read in chunks
    chunks_processed = 0
    total_cleaned = 0

    for chunk_df in pd.read_sql('SELECT * FROM tg_reviews_table', engine, chunksize=chunk_size):
        # Store original NA count
        original_nas = chunk_df.isna().sum().sum()

        # Clean numeric columns
        numeric_columns = chunk_df.select_dtypes(include=['int64', 'float64']).columns
        for col in numeric_columns:
            chunk_df[col] = chunk_df[col].fillna(chunk_df[col].median())

        # Clean categorical columns
        categorical_columns = chunk_df.select_dtypes(include=['object']).columns
        for col in categorical_columns:
            chunk_df[col] = chunk_df[col].fillna(chunk_df[col].mode()[0])

        # Write back to database
        if chunks_processed == 0:
            # First chunk replaces the table
            chunk_df.to_sql('tg_reviews_table', engine, if_exists='replace', index=False)
        else:
            # Subsequent chunks append
            chunk_df.to_sql('tg_reviews_table', engine, if_exists='append', index=False)

        total_cleaned += original_nas - chunk_df.isna().sum().sum()
        chunks_processed += 1

    return f"""Cleaning completed successfully:
    - Chunks processed: {chunks_processed}
    - Total NA values cleaned: {total_cleaned}"""
---

