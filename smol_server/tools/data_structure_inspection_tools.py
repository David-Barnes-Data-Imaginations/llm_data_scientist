import pandas as pd
from smolagents import tool
import numpy as np


@tool
def analyze_data_patterns(chunk: list[dict], analysis_type: str) -> dict:
    """
    Analyzes specific patterns in the data chunk based on the specified analysis type.

    Parameters:
    chunk (list[dict]): List of dictionaries containing the data
    analysis_type (str): Type of analysis to perform:
        - 'demographic': Age/gender/education patterns
        - 'review_sentiment': Analysis of review text patterns
        - 'spending_patterns': Relationship between spending and other factors
        - 'platform_specific': Platform-based patterns

    Returns:
    dict: Analysis results with patterns found, including:
        - Statistical distributions
        - Correlations
        - Aggregated metrics by category

    Example input:
    chunk = [
        {'age': 35, 'gender': 'Male', 'education': 'Bachelor', 'spending_score (1-100)': 85},
        {'age': 28, 'gender': 'Female', 'education': 'Master', 'spending_score (1-100)': 92}
    ]
    analysis_type = 'demographic'
    """
    df = pd.DataFrame(chunk)
    patterns = {}

    if analysis_type == 'demographic':
        patterns['age_distribution'] = df['age'].describe()
        patterns['education_by_age'] = df.groupby('education')['age'].agg(['mean', 'std'])
        patterns['spending_by_gender'] = df.groupby('gender')['spending_score (1-100)'].mean()

    elif analysis_type == 'review_sentiment':
        # Basic sentiment patterns in reviews
        patterns['avg_review_length'] = df['review'].str.len().mean()
        patterns['common_words'] = df['review'].str.split().explode().value_counts().head(10)

    elif analysis_type == 'spending_patterns':
        patterns['spending_by_education'] = df.groupby('education')['spending_score (1-100)'].mean()
        patterns['loyalty_spending_corr'] = df['spending_score (1-100)'].corr(df['loyalty_points'])

    elif analysis_type == 'platform_specific':
        patterns['platform_demographics'] = df.groupby('platform').agg({
            'age': 'mean',
            'spending_score (1-100)': 'mean',
            'loyalty_points': 'mean'
        })

    return patterns



@tool
def run_check_dataframe(chunk: list[dict]) -> str:
    """
    Inspects a pandas DataFrame for any non-numeric, NaN, or infinite values.

    Parameters:
    chunk (list[dict]): List of dictionaries to be converted to DataFrame and checked.

    Returns:
    str: Success message if no issues are found.

    Raises:
    ValueError: If the DataFrame contains any non-numeric, NaN, or infinite values.

    Example input:
    chunk = [
        {'feature1': 10, 'feature2': 20},
        {'feature1': 30, 'feature2': 40}
    ]
    """
    # Convert a list of dictionaries to DataFrame
    df = pd.DataFrame(chunk)

    # Ensure it contains only numeric data
    if not df.select_dtypes(include=['number']).shape[1] == df.shape[1]:
        raise ValueError("DataFrame contains non-numeric data. Consider encoding these columns.")

    # Check for NaN values
    if df.isnull().any().any():
        raise ValueError("DataFrame contains NaN values. Consider filling or dropping these columns.")

    # Check for Inf values
    if np.isinf(df.values).any():
        raise ValueError("DataFrame contains Inf values. Consider handling these columns.")

    return "DataFrame validation passed successfully"

@tool
def inspect_dataframe(df):
    """
    Inspects and provides a comprehensive overview of a pandas DataFrame.

    Parameters:
    df (pandas.DataFrame): The DataFrame to inspect and analyze.

    Returns:
    pandas.DataFrame: A DataFrame containing descriptive statistics for all columns,
                     generated by pandas' describe() method with include='all'.

    Example input:
    df = pd.DataFrame({
        'numeric': [1, 2, 3, 4, 5],
        'categorical': ['A', 'B', 'A', 'C', 'B']
    })
    """
    print(df.head())
    print("\nShape:")
    print(df.shape)
    print("\nColumns:")
    print(df.columns)
    print("\nDescriptive Statistics:")
    # describe() only analyses numeric data by default.
    # To include categorical columns
    # in the summary statistics, an argument can be added to the describe() method.
    return df.describe(include='all')
